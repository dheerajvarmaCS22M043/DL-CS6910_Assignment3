{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from pandas.core.reshape.pivot import pivot\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "# from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "\n",
        "# from torch import optim\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "2wVabjz3qdvE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "23be2e28-7e4e-4e94-a352-a208c619c2bb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)"
      ],
      "metadata": {
        "id": "kDWwcnDGBl6U"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VNyUrkUfBp8M",
        "outputId": "61d2ec85-54f2-46ee-aef3-cf843822a897"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.23.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "eYccTEjiCNGY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key='6264e29f109d3cf02a9911cd18b6725b79c489cd')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YIFAsysxClZQ",
        "outputId": "7553f6f6-9576-4c8e-9d71-8bb8a2834cf3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m043\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "import gdown \n",
        "# !conda install -y gdown\n",
        "import zipfile\n",
        "url = 'https://drive.google.com/u/0/uc?id=1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw&export=download'  \n",
        "gdown.download(url)\n",
        "z= zipfile.ZipFile('aksharantar_sampled.zip')\n",
        "z.extractall()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Wi4uEB7us20p",
        "outputId": "84de09b4-45cb-4489-89b3-b9def5af7f65"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw&export=download\n",
            "To: /content/aksharantar_sampled.zip\n",
            "100%|██████████| 14.0M/14.0M [00:00<00:00, 159MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"aksharantar_sampled/tel/tel_train.csv\" , header = None)\n",
        "# df.head()\n",
        "df_val = pd.read_csv(\"aksharantar_sampled/tel/tel_valid.csv\" , header = None)\n",
        "df_test = pd.read_csv(\"aksharantar_sampled/tel/tel_test.csv\" , header = None)\n",
        "x1 = 0\n",
        "english_words_val = df_val[x1]\n",
        "english_words_test = df_test[x1]\n",
        "english_words = df[x1]\n",
        "telugu_words_val = df_val[x1+1]\n",
        "telugu_words_test = df_test[x1+1]\n",
        "telugu_words = df[x1+1]\n",
        "#print(df[50000:])"
      ],
      "metadata": {
        "id": "-8NGSmE_tnDW"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findCharList(eng_words,tel_words):\n",
        "  english_char_list = []\n",
        "  max_length_word_english = -1\n",
        "  telugu_char_list = []\n",
        "  max_length_word_telugu = -1\n",
        "  for word in eng_words:\n",
        "    x2 = len(word)\n",
        "    x3 = max(max_length_word_english,x2)\n",
        "    max_length_word_english = x3\n",
        "    for char in word :\n",
        "      c = char\n",
        "      english_char_list.append(c);\n",
        "  english_char_list = set(english_char_list)\n",
        "  english_char_list = list(english_char_list)\n",
        "  for word in tel_words:\n",
        "    x4 = len(word)\n",
        "    x5 = max(max_length_word_telugu,x4)\n",
        "    max_length_word_telugu = x5\n",
        "    for char in word :\n",
        "      c1 =char\n",
        "      telugu_char_list.append(c1);\n",
        "  telugu_char_list = set(telugu_char_list)\n",
        "  telugu_char_list = list(telugu_char_list)\n",
        "  english_char_list.sort()\n",
        "  telugu_char_list.sort()\n",
        "  # print(len(telugu_char_list))\n",
        "  #print(telugu_char_list)\n",
        "  print(len(telugu_char_list))\n",
        "  print(len(english_char_list))\n",
        "  return english_char_list,telugu_char_list,max_length_word_english,max_length_word_telugu"
      ],
      "metadata": {
        "id": "qpFjT-GZwshE"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_char_list,telugu_char_list,max_length_word_english,max_length_word_telugu=findCharList(english_words,telugu_words)\n",
        "print(english_char_list)\n",
        "print(telugu_char_list)\n",
        "print(max_length_word_telugu)\n",
        "print(max_length_word_english)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LgPkLaOjxls3",
        "outputId": "80f8f52e-5cb9-49f9-bbd9-c2425ea3a362"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62\n",
            "26\n",
            "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "['ం', 'ః', 'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ', 'క', 'ఖ', 'గ', 'ఘ', 'చ', 'ఛ', 'జ', 'ఝ', 'ఞ', 'ట', 'ఠ', 'డ', 'ఢ', 'ణ', 'త', 'థ', 'ద', 'ధ', 'న', 'ప', 'ఫ', 'బ', 'భ', 'మ', 'య', 'ర', 'ఱ', 'ల', 'ళ', 'వ', 'శ', 'ష', 'స', 'హ', 'ా', 'ి', 'ీ', 'ు', 'ూ', 'ృ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', '్']\n",
            "21\n",
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for one word.\n",
        "def english_word2vec(word):\n",
        "  vec = []\n",
        "  x6 = len(english_char_list)+1\n",
        "  vec.append(x6)\n",
        "  for char in word:\n",
        "    c = char\n",
        "    x7 = len(english_char_list)\n",
        "    for i in range(x7):\n",
        "      x8 = english_char_list[i]\n",
        "      if(x8 == c):\n",
        "        vec.append(i+1)\n",
        "  x9 = max_length_word_english + 1\n",
        "  while(len(vec) < x9): \n",
        "      x10 = 0\n",
        "      vec.append(x10)\n",
        "  x11 = 0\n",
        "  vec.append(x11)\n",
        "  return (vec)"
      ],
      "metadata": {
        "id": "YdWiHudL00KX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def telugu_word2vec(word):\n",
        "  vec = []\n",
        "  x6 = len(telugu_char_list)+1\n",
        "  vec.append(x6)\n",
        "  for char in word:\n",
        "    c = char\n",
        "    x7 = len(telugu_char_list)\n",
        "    for i in range(x7):\n",
        "      x8 = telugu_char_list[i]\n",
        "      if(x8 == c):\n",
        "        vec.append(i+1)\n",
        "  x9 = max_length_word_telugu + 1\n",
        "  while(len(vec) < x9):  \n",
        "      x10 = 0\n",
        "      vec.append(x10)\n",
        "  x11 = 0\n",
        "  vec.append(x11)\n",
        "  return(vec)"
      ],
      "metadata": {
        "id": "sI523riu1gFh"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec = telugu_word2vec(telugu_words[10])\n",
        "print(telugu_words[10])\n",
        "print(vec)\n",
        "print(\"dheeraj\")"
      ],
      "metadata": {
        "id": "84cRh6as1VxI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1490e526-5f80-4e03-d82e-a7cf8efa869b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "వైఖరిలోను\n",
            "[63, 45, 58, 17, 41, 51, 43, 60, 34, 53, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "dheeraj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec = english_word2vec(english_words[10])\n",
        "print(english_words[10])\n",
        "print(vec)\n",
        "print(\"varma\")"
      ],
      "metadata": {
        "id": "DuGljP2vsFNR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7a329cf6-b424-4f66-cbcf-14da209a05cf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vaikhariloonu\n",
            "[27, 22, 1, 9, 11, 8, 1, 18, 9, 12, 15, 15, 14, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "varma\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = []\n",
        "gt=[]\n",
        "inp = []"
      ],
      "metadata": {
        "id": "f6ltWH3-PSnO"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating matrix of representation for whole words of english and telugu.\n",
        "\n",
        "def ip_matrix_construct(words, lang):\n",
        "  ans = []\n",
        "  if(lang == \"english\"):\n",
        "    for word in words:\n",
        "      ans.append(english_word2vec(word))\n",
        "  else:\n",
        "    for word in words:\n",
        "      ans.append(telugu_word2vec(word))\n",
        "  return(ans)"
      ],
      "metadata": {
        "id": "d1wG87o92bfL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matrixRep(english_words,telugu_words,english_words_val,telugu_words_val,english_words_test,telugu_words_test):\n",
        "  # calculated representations of whole english and marathi words in variables english and marathi matrix.\n",
        "  eng = \"english\"\n",
        "  english_matrix = ip_matrix_construct(english_words, eng)\n",
        "  \n",
        "  english_matrix_val = ip_matrix_construct(english_words_val, eng)\n",
        "  english_matrix_test = ip_matrix_construct(english_words_test, eng)\n",
        "  \n",
        "  \n",
        "  english_matrix = torch.tensor(english_matrix)\n",
        "  english_matrix_val = torch.tensor(english_matrix_val)\n",
        "  english_matrix_test = torch.tensor(english_matrix_test)\n",
        "  \n",
        "  tel = \"telugu\"\n",
        "  telugu_matrix = ip_matrix_construct(telugu_words, tel)\n",
        " \n",
        "  telugu_matrix_val = ip_matrix_construct(telugu_words_val, tel)\n",
        "  telugu_matrix_test =ip_matrix_construct(telugu_words_test, tel)\n",
        "\n",
        "  telugu_matrix = torch.tensor(telugu_matrix) \n",
        "  telugu_matrix_val = torch.tensor(telugu_matrix_val)\n",
        "  telugu_matrix_test = torch.tensor(telugu_matrix_test)\n",
        "  \n",
        "  return english_matrix,telugu_matrix,english_matrix_val,telugu_matrix_val,english_matrix_test,telugu_matrix_test"
      ],
      "metadata": {
        "id": "xoDyG2_pDeap"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_matrix,telugu_matrix,english_matrix_val,telugu_matrix_val,english_matrix_test,telugu_matrix_test = matrixRep(english_words,telugu_words,english_words_val,telugu_words_val,english_words_test,telugu_words_test)"
      ],
      "metadata": {
        "id": "dbUc6SD0QqBa"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,input_size, embedding_size, hidden_size, num_layers, dropout, cell_type, bidirectional,s=0.1):\n",
        "    super(Encoder,self).__init__()\n",
        "    ct = cell_type\n",
        "    self.cell_type = ct\n",
        "    dp = dropout\n",
        "    self.dropout = nn.Dropout(dp)\n",
        "    bd = bidirectional\n",
        "    self.bidirectional = bd\n",
        "    hs = hidden_size\n",
        "    self.hidden_size = hs\n",
        "    iS = input_size \n",
        "    self.embedding = nn.Embedding(iS, embedding_size)\n",
        "    nl = num_layers\n",
        "    self.num_layers = nl\n",
        "    s1 = s\n",
        "    self.s = s1\n",
        "    if(ct == \"LSTM\"):\n",
        "      self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = dropout, bidirectional = bidirectional)\n",
        "    elif(cell_type == \"RNN\"):\n",
        "      self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout = dropout, bidirectional = bidirectional)\n",
        "    elif(ct == \"GRU\"):\n",
        "      s1 = s1*2\n",
        "      self.gru = nn.GRU(embedding_size, hidden_size, num_layers, dropout = dropout, bidirectional = bidirectional)\n",
        "\n",
        "  def forward(self, x):\n",
        "    k = x\n",
        "    embedding = self.dropout(self.embedding(k))\n",
        "    ct1 = self.cell_type\n",
        "    if(ct1 == \"LSTM\"):\n",
        "      outputs, (hidden,cell) = self.lstm(embedding)\n",
        "      return hidden, cell\n",
        "    elif(ct1 == \"GRU\"):\n",
        "      output, hidden = self.gru(embedding)\n",
        "      return output, hidden\n",
        "    elif(ct1 == \"RNN\"):\n",
        "      output, hidden = self.rnn(embedding)\n",
        "      return output, hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-04T18:50:06.287093Z",
          "iopub.status.busy": "2023-05-04T18:50:06.286735Z",
          "iopub.status.idle": "2023-05-04T18:50:06.298555Z",
          "shell.execute_reply": "2023-05-04T18:50:06.297751Z"
        },
        "id": "abbae9cd",
        "papermill": {
          "duration": 0.026877,
          "end_time": "2023-05-04T18:50:06.300723",
          "exception": false,
          "start_time": "2023-05-04T18:50:06.273846",
          "status": "completed"
        },
        "tags": []
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, dropout, cell_type,s=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "    ct = cell_type\n",
        "    self.cell_type = ct\n",
        "    hs = hidden_size\n",
        "    self.hidden_size = hs\n",
        "    dp = dropout\n",
        "    self.dropout = nn.Dropout(dp)\n",
        "    iS = input_size\n",
        "    self.embedding = nn.Embedding(iS, embedding_size)\n",
        "    self.s = s\n",
        "    nl = num_layers\n",
        "    self.num_layers = nl\n",
        "   \n",
        "    if(ct == \"LSTM\"):\n",
        "      self.lstm = nn.LSTM(embedding_size, hs, nl, dropout = dp)\n",
        "      es=embedding_size\n",
        "    elif(ct == \"GRU\"):\n",
        "      self.gru = nn.GRU(embedding_size, hs, nl, dropout = dp)\n",
        "    elif(ct == \"RNN\"):\n",
        "      self.rnn = nn.RNN(embedding_size, hs, nl, dropout = dp)\n",
        "      s=s*2\n",
        "    self.fc = nn.Linear(hs, output_size)  # fully connected.\n",
        "  \n",
        "  def forward(self, x, hidden, cell = 0):\n",
        "    y = x\n",
        "    y = y.unsqueeze(0).int()\n",
        "    embedding = self.dropout(self.embedding(y))\n",
        "    ct1 = self.cell_type\n",
        "\n",
        "    if(ct1 == \"LSTM\"):\n",
        "        outputs, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n",
        "    elif(ct1 == \"RNN\"):\n",
        "        outputs, hidden = self.rnn(embedding, hidden)\n",
        "    elif(ct1 == \"GRU\"):\n",
        "        outputs, hidden = self.gru(embedding, hidden)\n",
        " \n",
        "    predictions = self.fc(outputs)\n",
        "    predictions = predictions.squeeze(0)\n",
        "    if(ct1 == \"LSTM\"):\n",
        "        return predictions, hidden, cell\n",
        "    else:\n",
        "        return predictions, hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "sk0Uvabyo7iz"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, cell_type, bidirectional, num_layers,s=0.1):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        nl = num_layers\n",
        "        self.num_layers = nl\n",
        "        bd = bidirectional\n",
        "        self.bidirectional = bd\n",
        "        ct = cell_type\n",
        "        self.s = s\n",
        "        self.cell_type = ct\n",
        "        \n",
        "\n",
        "    def forward(self, source, target, teacher_force_ratio=0.5,p=0.1):\n",
        "        t2 = target.shape[0]\n",
        "        target_len = t2\n",
        "        s2 = source.shape[1]\n",
        "        batch_size = s2\n",
        "        tcl = len(telugu_char_list)\n",
        "        target_vocab_size = tcl + 2  # intitially = 66 || Now 63 + 1(start token) + 1 = 65\n",
        "        tvs = target_vocab_size\n",
        "        outputs = torch.zeros(t2, s2, tvs).to(device)\n",
        "        ct3 = self.cell_type\n",
        "        if(ct3 == \"GRU\"):\n",
        "            output, hidden = self.encoder(source)\n",
        "        elif(ct3 == \"RNN\"):\n",
        "            output, hidden = self.encoder(source)\n",
        "        else:\n",
        "            hidden, cell = self.encoder(source)\n",
        "        bd3 = self.bidirectional \n",
        "        sl3 = self.num_layers\n",
        "        if(bd3 == True):\n",
        "            hidden = hidden[sl3 - 1] + hidden[sl3 - 1]\n",
        "            hidden = hidden.repeat(sl3,1,1)\n",
        "            if(self.cell_type == \"LSTM\"):\n",
        "                cell = cell[sl3 - 1] + cell[sl3 - 1]\n",
        "                cell = cell.repeat(sl3,1,1)\n",
        "                \n",
        "        x = target[0]\n",
        "        s5=0.2\n",
        "        for t in range(t2-1):\n",
        "            if(ct3 == \"LSTM\"):\n",
        "                output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "                s5=s5*2\n",
        "            else :\n",
        "                output, hidden = self.decoder(x, hidden)\n",
        "                s5=s5+2\n",
        "\n",
        "            outputs[t+1] = output\n",
        "            best_guess = output.argmax(1)\n",
        "            y = output\n",
        "            x = target[t+1] if random.random() < teacher_force_ratio else best_guess\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "N3etjdNwp0Jk"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def findDecoderInputSize():\n",
        "#   x = len(telugu_char_list)\n",
        "#   return x"
      ],
      "metadata": {
        "id": "1uuTRKiebHbc"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def findEncoderInputSize():\n",
        "#   x = len(english_char_list)\n",
        "#   return x"
      ],
      "metadata": {
        "id": "SkbDXhlna2C5"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Evaluate(model, english_matrix, telugu_matrix, epoch, batch_size,s=0.1):\n",
        "    correct_count = 0\n",
        "    bat = (int)(len(english_matrix) / batch_size)\n",
        "    for batch_idx in range(1,bat+1):\n",
        "        inp_data = english_matrix[batch_size * (batch_idx-1) : batch_size * (batch_idx)].to(device)\n",
        "        id = inp_data\n",
        "        bs = batch_size\n",
        "        target = telugu_matrix[bs * (batch_idx-1) : bs * (batch_idx)].to(device)\n",
        "        tgt = target\n",
        "        # print(len(target))\n",
        "        # print(type(target))\n",
        "        # print(\"dheeraj1\")\n",
        "        # print(target[0])\n",
        "        output = model.forward(id.T, tgt.T, 0)\n",
        "        s1=s\n",
        "        # print(output[0])\n",
        "        # print(\"varma1\")\n",
        "        # print(target[0])\n",
        "        output = nn.Softmax(dim=2)(output)\n",
        "        #s1=s1*bs\n",
        "        output = torch.argmax(output, dim=2)\n",
        "        ot = output\n",
        "        output = ot.T\n",
        "\n",
        "        for i in range(1,bs+1):\n",
        "            if(torch.equal(output[i-1][1:],target[i-1][1:])):\n",
        "                k = correct_count\n",
        "                correct_count = k+1\n",
        "    l5 = len(english_matrix)\n",
        "    accuracy = correct_count * 100 / l5\n",
        "    return accuracy\n",
        "        "
      ],
      "metadata": {
        "id": "Eo2VDhLNw4VA"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_words(model, english_matrix, telugu_matrix, batch_size):\n",
        "  bs=batch_size\n",
        "  count=0\n",
        "  for batch_idx in range((int)(len(english_matrix) / bs)):\n",
        "        inp_data = english_matrix[bs * batch_idx : bs * (batch_idx+1)].to(device)\n",
        "        inp_data1=inp_data\n",
        "        target = telugu_matrix[batch_size * batch_idx : batch_size * (batch_idx+1)].to(device)\n",
        "        output = model.forward(inp_data.T, target.T, 0)\n",
        "        count=count+bs\n",
        "        output = nn.Softmax(dim=2)(output)\n",
        "        output = torch.argmax(output, dim=2)\n",
        "        gt1=[]\n",
        "        output = output.T\n",
        "        count=count/(batch_idx+1)\n",
        "        for i in range(len(inp_data)):\n",
        "          inp_word = inp_data[i]\n",
        "          word = \"\"\n",
        "          for j in range(len(inp_word)):\n",
        "            eng_char_array_size=27\n",
        "            if(inp_word[j]>0 and inp_word[j]<eng_char_array_size):\n",
        "              word += english_char_list[inp_word[j]-1]\n",
        "          #temp1 = [word]\n",
        "          #if(data_type == \"test\"):\n",
        "          inp.append(word)\n",
        "        for i in range(len(target)):\n",
        "          word1 = \"\"\n",
        "          word2 = \"\"\n",
        "          target_word = target[i]\n",
        "          output_word = output[i]\n",
        "          gt1.append(output_word)\n",
        "          for j in range(len(target_word)):\n",
        "            if(target_word[j]>0 and target_word[j]<63):\n",
        "              word1 += telugu_char_list[target_word[j] - 1]\n",
        "          count1=count\n",
        "          for j in range(len(output_word)):\n",
        "            if(output_word[j]>0 and output_word[j]<63):\n",
        "              word2 = word2 + telugu_char_list[output_word[j] - 1]\n",
        "          temp = [word1, word2]\n",
        "          \n",
        "          gt.append(temp[0])\n",
        "          pred.append(temp[1])\n",
        "        \n",
        "  df_test = pd.DataFrame({\"Input\": inp, \"Ground Truth\" : gt, \"Model output\":pred})\n",
        "  df_test.to_csv(\"prediction_vanilla.csv\", index=False)\n",
        "            "
      ],
      "metadata": {
        "id": "UhvIq2DbQ9YA"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neural_network(cell_type, bidirectional, num_layers, batch_size, embedding_size, hidden_size, dropout,num_epochs=5,learning_rate=0.001):\n",
        "  x=len(english_char_list)\n",
        "  y=len(telugu_char_list)\n",
        "  input_size_encoder = x + 2   \n",
        "  input_size_decoder = y + 2  \n",
        "  output_size        = y + 2  \n",
        "  s=0.2\n",
        "  encoder_net = Encoder(input_size_encoder, embedding_size, hidden_size, num_layers, dropout, cell_type,bidirectional).to(device)\n",
        "  s=s+1\n",
        "  decoder_net = Decoder(input_size_decoder,embedding_size,hidden_size,output_size,num_layers,dropout, cell_type).to(device)\n",
        "  pad_idx = 63\n",
        "  model = Seq2Seq(encoder_net, decoder_net, cell_type, bidirectional, num_layers).to(device)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  \n",
        "  criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "  # train_loss = []\n",
        "  # train_accuracy = []\n",
        "  # val_accuracy = []\n",
        "  for epoch in range(1,num_epochs+1):\n",
        "      ep = epoch-1\n",
        "      print(\"epoch = \",ep)\n",
        "\n",
        "      model.train()\n",
        "      step = 0\n",
        "      total_loss = 0\n",
        "      bat = (int)(len(english_matrix) / batch_size)\n",
        "      for batch_idx in range(1,bat+1):\n",
        "          \n",
        "          bi = batch_idx\n",
        "          inp_data = english_matrix[batch_size * (bi-1) : batch_size * (bi)].to(device)\n",
        "          target = telugu_matrix[batch_size * (bi-1) : batch_size * (bi)].to(device)\n",
        "\n",
        "          target = target.T\n",
        "          output = model(inp_data.T, target)\n",
        "          step1 = step\n",
        "          output = output[1:].reshape(-1, output.shape[2])\n",
        "          s=0\n",
        "          target = target[1:].reshape(-1)\n",
        "          optimizer.zero_grad()\n",
        "          loss = criterion(output, target)\n",
        "          l1 = loss\n",
        "          total_loss = total_loss + loss\n",
        "          loss.backward()\n",
        "\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "          optimizer.step()\n",
        "          s=s+1\n",
        "          step = step + 1\n",
        "  #     print(\"total loss = \",total_loss / (len(english_matrix) * len(marathi_matrix[0])))\n",
        "      tl = total_loss/step\n",
        "      print(\"total loss = \",tl)\n",
        "      #train_loss.append(tl)\n",
        "\n",
        "      # training_accuracy = Evaluate(model, english_matrix, telugu_matrix, ep, batch_size)\n",
        "      # print(\"Training Accuracy = \", training_accuracy)\n",
        "      # s+=1\n",
        "      # #train_accuracy.append(training_accuracy)\n",
        "      # val_accuracy = Evaluate(model, english_matrix_val, telugu_matrix_val, ep, batch_size)\n",
        "      # print(\"Validation accuracy = \",val_accuracy)\n",
        "      # test_accuracy = Evaluate(model, english_matrix_test, telugu_matrix_test, ep, batch_size)\n",
        "      # print(\"Test accuracy = \",test_accuracy)\n",
        "      #wandb.log({\"train_accuracy\": training_accuracy, \"validation_accuracy\": val_accuracy, \"training_loss\": total_loss / step,  'epoch': ep})\n",
        "  #return train_loss,train_accuracy,val_accuracy\n",
        "  test_accuracy = Evaluate(model, english_matrix_test, telugu_matrix_test, num_epochs, batch_size)\n",
        "  print(\"Test accuracy = \",test_accuracy)\n",
        "  to_words(model, english_matrix_test, telugu_matrix_test, batch_size)"
      ],
      "metadata": {
        "id": "a9NHrnmtzxMG"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#best hyperparameters\n",
        "cell_type = \"LSTM\"\n",
        "bidirectional = True\n",
        "num_layers = 2\n",
        "batch_size = 128\n",
        "embedding_size = 128\n",
        "hidden_size = 512\n",
        "dropout = 0.4\n",
        "num_epochs = 15\n",
        "learning_rate = 0.001\n",
        "neural_network(cell_type, bidirectional, num_layers, batch_size, embedding_size, hidden_size, dropout, num_epochs, learning_rate)"
      ],
      "metadata": {
        "id": "3jhaic16Q7YY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6b971547-e3fd-4531-87ae-bc2420155290"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch =  0\n",
            "total loss =  tensor(0.8946, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch =  1\n",
            "total loss =  tensor(0.3339, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch =  2\n",
            "total loss =  tensor(0.2266, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch =  3\n",
            "total loss =  tensor(0.1810, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch =  4\n",
            "total loss =  tensor(0.1537, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch =  5\n",
            "total loss =  tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch =  6\n",
            "total loss =  tensor(0.1160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch =  7\n",
            "total loss =  tensor(0.1041, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch =  8\n",
            "total loss =  tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch =  9\n",
            "total loss =  tensor(0.0811, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch =  10\n",
            "total loss =  tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch =  11\n",
            "total loss =  tensor(0.0656, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch =  12\n",
            "total loss =  tensor(0.0611, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch =  13\n",
            "total loss =  tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "epoch =  14\n",
            "total loss =  tensor(0.0494, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Test accuracy =  48.0712890625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(pvt[0][1])\n",
        "# print(pvt[1][0])\n",
        "# print(pvt[1][1])"
      ],
      "metadata": {
        "id": "8kQlFVmMhb1s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cca67ce4-a809-49d4-f2d0-b25b11ab2f87"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "వితనాన్ని\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"prediction_vanilla.csv\")\n",
        "df_test = df_test.sample(frac=1)\n",
        "df_test.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "bf5I0G99KbSx",
        "outputId": "3c53071d-ded0-4ae3-d570-f3058e5f1aaa"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    Input       Ground Truth       Model output\n",
              "1385            coachella           కోచెల్లా            కాచెళ్ల\n",
              "2253  digajaarchukuntunna  దిగజార్చుకుంటున్న  దిగజార్చుకుంటున్న\n",
              "2343           ahaaramtoo            ఆహారంతో            ఆహారంతో\n",
              "2659                  kar                కర్                కర్\n",
              "1122               cheppe             చెప్పే             చెప్పే\n",
              "2222           aakaaraalu            ఆకారాలు            ఆకారాలు\n",
              "1346              fleming          ఫ్లెమింగ్          ఫ్లెమింగ్\n",
              "668                  dial               డయల్             డియాల్\n",
              "1188         rakshanhagaa            రక్షణగా            రక్షణగా\n",
              "3460       bhavincheevaru        భావించేవారు        భావించేవారు\n",
              "714           jatilamaina            జటిలమైన           జాటీలమైన\n",
              "2434             lakhmani             లక్మని            లఖ్మాని\n",
              "2409              hechdee             హెచ్డీ             హెచ్డీ\n",
              "2410     mataachaaraalanu         మతాచారాలను         మతాచారాలను\n",
              "2969              mcmahon          మెక్మోహన్           మెక్మాన్\n",
              "3581          rojurojukoo         రోజురోజుకూ         రోజురోజుకూ\n",
              "665                 kaali               కాళీ               కాలి\n",
              "1382              kotturu           కొత్తూరు           కొట్టురు\n",
              "2724                 lara               లారా               లారా\n",
              "2173                mitra              మిత్ర             మిత్రా"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bbdc55f4-81cc-4afb-9c1f-6e4ab2eae860\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input</th>\n",
              "      <th>Ground Truth</th>\n",
              "      <th>Model output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1385</th>\n",
              "      <td>coachella</td>\n",
              "      <td>కోచెల్లా</td>\n",
              "      <td>కాచెళ్ల</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2253</th>\n",
              "      <td>digajaarchukuntunna</td>\n",
              "      <td>దిగజార్చుకుంటున్న</td>\n",
              "      <td>దిగజార్చుకుంటున్న</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2343</th>\n",
              "      <td>ahaaramtoo</td>\n",
              "      <td>ఆహారంతో</td>\n",
              "      <td>ఆహారంతో</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2659</th>\n",
              "      <td>kar</td>\n",
              "      <td>కర్</td>\n",
              "      <td>కర్</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1122</th>\n",
              "      <td>cheppe</td>\n",
              "      <td>చెప్పే</td>\n",
              "      <td>చెప్పే</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2222</th>\n",
              "      <td>aakaaraalu</td>\n",
              "      <td>ఆకారాలు</td>\n",
              "      <td>ఆకారాలు</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1346</th>\n",
              "      <td>fleming</td>\n",
              "      <td>ఫ్లెమింగ్</td>\n",
              "      <td>ఫ్లెమింగ్</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>668</th>\n",
              "      <td>dial</td>\n",
              "      <td>డయల్</td>\n",
              "      <td>డియాల్</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1188</th>\n",
              "      <td>rakshanhagaa</td>\n",
              "      <td>రక్షణగా</td>\n",
              "      <td>రక్షణగా</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3460</th>\n",
              "      <td>bhavincheevaru</td>\n",
              "      <td>భావించేవారు</td>\n",
              "      <td>భావించేవారు</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>714</th>\n",
              "      <td>jatilamaina</td>\n",
              "      <td>జటిలమైన</td>\n",
              "      <td>జాటీలమైన</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2434</th>\n",
              "      <td>lakhmani</td>\n",
              "      <td>లక్మని</td>\n",
              "      <td>లఖ్మాని</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2409</th>\n",
              "      <td>hechdee</td>\n",
              "      <td>హెచ్డీ</td>\n",
              "      <td>హెచ్డీ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2410</th>\n",
              "      <td>mataachaaraalanu</td>\n",
              "      <td>మతాచారాలను</td>\n",
              "      <td>మతాచారాలను</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2969</th>\n",
              "      <td>mcmahon</td>\n",
              "      <td>మెక్మోహన్</td>\n",
              "      <td>మెక్మాన్</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3581</th>\n",
              "      <td>rojurojukoo</td>\n",
              "      <td>రోజురోజుకూ</td>\n",
              "      <td>రోజురోజుకూ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665</th>\n",
              "      <td>kaali</td>\n",
              "      <td>కాళీ</td>\n",
              "      <td>కాలి</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1382</th>\n",
              "      <td>kotturu</td>\n",
              "      <td>కొత్తూరు</td>\n",
              "      <td>కొట్టురు</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2724</th>\n",
              "      <td>lara</td>\n",
              "      <td>లారా</td>\n",
              "      <td>లారా</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2173</th>\n",
              "      <td>mitra</td>\n",
              "      <td>మిత్ర</td>\n",
              "      <td>మిత్రా</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbdc55f4-81cc-4afb-9c1f-6e4ab2eae860')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bbdc55f4-81cc-4afb-9c1f-6e4ab2eae860 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bbdc55f4-81cc-4afb-9c1f-6e4ab2eae860');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sweep_config = {\n",
        "#     \"method\": 'bayes', #grid, random\n",
        "#     \"metric\": {\n",
        "#       \"name\": 'validation_accuracy',\n",
        "#       \"goal\": 'maximize', \n",
        "#     },\n",
        "#     \"parameters\": {\n",
        "#         \"epochs\": {\n",
        "#             \"values\": [15]\n",
        "#         },\n",
        "#         \"dropout\": {\n",
        "#             \"values\": [0.5]\n",
        "#         },\n",
        "#         \"hidden_size\": {\n",
        "#             \"values\": [256]\n",
        "#         },\n",
        "#         \"embedding_size\": {\n",
        "#             \"values\": [128]\n",
        "#         },\n",
        "#         \"learning_rate\":{\n",
        "#             \"values\":[0.001]\n",
        "#         },\n",
        "#         \"batch_size\":{\n",
        "#             \"values\":[128]\n",
        "#         },\n",
        "#         \"num_layers\":{\n",
        "#             \"values\":[2]\n",
        "#        },\n",
        "#         \"bidirectional\":{\n",
        "#             \"values\":[False]\n",
        "#         },\n",
        "#         \"cell_type\":{\n",
        "#             \"values\":['LSTM']\n",
        "#         }\n",
        "#     }\n",
        "# }"
      ],
      "metadata": {
        "id": "i2k3u7LQg-nL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sweep_config = {\n",
        "#     \"method\": 'bayes', #grid, random\n",
        "#     \"metric\": {\n",
        "#       \"name\": 'validation_accuracy',\n",
        "#       \"goal\": 'maximize', \n",
        "#     },\n",
        "#     \"parameters\": {\n",
        "#         \"epochs\": {\n",
        "#             \"values\": [15]\n",
        "#         },\n",
        "#         \"dropout\": {\n",
        "#             \"values\": [0.3,0.4,0.5]\n",
        "#         },\n",
        "#         \"hidden_size\": {\n",
        "#             \"values\": [128,256,512]\n",
        "#         },\n",
        "#         \"embedding_size\": {\n",
        "#             \"values\": [128,256,512]\n",
        "#         },\n",
        "#         \"learning_rate\":{\n",
        "#             \"values\":[0.001,0.05]\n",
        "#         },\n",
        "#         \"batch_size\":{\n",
        "#             \"values\":[32,64,128,256]\n",
        "#         },\n",
        "#         \"num_layers\":{\n",
        "#             \"values\":[1,3,2]\n",
        "#        },\n",
        "#         \"bidirectional\":{\n",
        "#             \"values\":[False,True]\n",
        "#         },\n",
        "#         \"cell_type\":{\n",
        "#             \"values\":['LSTM','RNN','GRU']\n",
        "#         }\n",
        "#     }\n",
        "# }"
      ],
      "metadata": {
        "id": "yU8GaMtMDaKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train():\n",
        "   \n",
        "#     wandb.init()\n",
        "\n",
        "#     #wandb.init()\n",
        "\n",
        "#     # Config is a variable that holds and saves hyperparameters and inputs\n",
        "#     config = wandb.config\n",
        "\n",
        "#     name=\"ct_\"+str(wandb.config.cell_type)+\"_bd_\"+str(wandb.config.bidirectional)+\"_nl_\"+str(wandb.config.num_layers)+\"_bs_\"+str(wandb.config.batch_size)+\"_es_\"+str(wandb.config.embedding_size)+\"_hs_\"+str(wandb.config.hidden_size)+\"_dp_\"+str(wandb.config.dropout)\n",
        "#     print(name)\n",
        "#     wandb.run.name = name\n",
        "   \n",
        "#     neural_network(cell_type=config.cell_type, bidirectional=config.bidirectional, num_layers=config.num_layers,batch_size = config.batch_size,embedding_size=config.embedding_size,hidden_size=config.hidden_size,dropout=config.dropout,num_epochs=config.epochs,learning_rate=config.learning_rate)\n",
        "\n",
        "  \n",
        "\n",
        "#     # for zi in range(len(train_acc)):\n",
        "#     #     print(zi)        \n",
        "#     #     wandb.log({'train_accuracy':train_acc[zi]})\n",
        "#     #     wandb.log({'val_accuracy':val_acc[zi]})\n",
        "#     #     wandb.log({'train_loss':train_loss[zi]}) \n",
        "#     #     #wandb.log({'val_loss':val_loss[zi]})\n",
        "#     #     wandb.log({'num_epochs':zi+1})\n",
        "\n",
        "#     wandb.finish()"
      ],
      "metadata": {
        "id": "--8rbYftWw1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sweep_id = wandb.sweep(sweep_config, entity=\"cs22m043\", project=\"Assignment3\")\n",
        "# wandb.agent(sweep_id, train, count=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2054
        },
        "id": "uZWVc5RgBFxS",
        "outputId": "4bf67c85-0702-42a1-82f7-f822d96f497a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: nqjwyyj7\n",
            "Sweep URL: https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nfyf87hy with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m043\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230518_154611-nfyf87hy</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m043/Assignment3/runs/nfyf87hy' target=\"_blank\">fiery-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m043/Assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m043/Assignment3' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m043/Assignment3/runs/nfyf87hy' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3/runs/nfyf87hy</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ct_LSTM_bd_False_nl_2_bs_128_es_128_hs_256_dp_0.5\n",
            "epoch =  0\n",
            "total loss =  tensor(1.5998, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  0.0\n",
            "Validation accuracy =  0.0\n",
            "epoch =  1\n",
            "total loss =  tensor(1.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  1.662109375\n",
            "Validation accuracy =  4.150390625\n",
            "epoch =  2\n",
            "total loss =  tensor(0.6458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  9.802734375\n",
            "Validation accuracy =  15.8447265625\n",
            "epoch =  3\n",
            "total loss =  tensor(0.4578, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  18.763671875\n",
            "Validation accuracy =  24.462890625\n",
            "epoch =  4\n",
            "total loss =  tensor(0.3707, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  24.75390625\n",
            "Validation accuracy =  27.587890625\n",
            "epoch =  5\n",
            "total loss =  tensor(0.3165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  31.138671875\n",
            "Validation accuracy =  33.837890625\n",
            "epoch =  6\n",
            "total loss =  tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  34.568359375\n",
            "Validation accuracy =  34.3505859375\n",
            "epoch =  7\n",
            "total loss =  tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  38.177734375\n",
            "Validation accuracy =  37.2314453125\n",
            "epoch =  8\n",
            "total loss =  tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  41.64453125\n",
            "Validation accuracy =  40.0634765625\n",
            "epoch =  9\n",
            "total loss =  tensor(0.2139, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  43.796875\n",
            "Validation accuracy =  41.1376953125\n",
            "epoch =  10\n",
            "total loss =  tensor(0.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  46.392578125\n",
            "Validation accuracy =  41.9677734375\n",
            "epoch =  11\n",
            "total loss =  tensor(0.1911, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  47.87890625\n",
            "Validation accuracy =  43.0419921875\n",
            "epoch =  12\n",
            "total loss =  tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  49.701171875\n",
            "Validation accuracy =  43.798828125\n",
            "epoch =  13\n",
            "total loss =  tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  50.869140625\n",
            "Validation accuracy =  44.921875\n",
            "epoch =  14\n",
            "total loss =  tensor(0.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  53.380859375\n",
            "Validation accuracy =  45.8740234375\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_accuracy</td><td>▁▁▂▃▄▅▆▆▆▇▇▇███</td></tr><tr><td>training_loss</td><td>█▆▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▂▃▅▅▆▆▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_accuracy</td><td>53.38086</td></tr><tr><td>training_loss</td><td>0.16245</td></tr><tr><td>validation_accuracy</td><td>45.87402</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fiery-sweep-1</strong> at: <a href='https://wandb.ai/cs22m043/Assignment3/runs/nfyf87hy' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3/runs/nfyf87hy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230518_154611-nfyf87hy/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9o9c69sn with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230518_155229-9o9c69sn</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m043/Assignment3/runs/9o9c69sn' target=\"_blank\">light-sweep-2</a></strong> to <a href='https://wandb.ai/cs22m043/Assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m043/Assignment3' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m043/Assignment3/runs/9o9c69sn' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3/runs/9o9c69sn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ct_LSTM_bd_False_nl_2_bs_128_es_128_hs_256_dp_0.5\n",
            "epoch =  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# id = wandb.sweep(sweep_config, project=\"Assignment3\", entity =\"cs22m043\")\n",
        "# wandb.agent(id, function=train)"
      ],
      "metadata": {
        "id": "wWumB8s4LuJG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}