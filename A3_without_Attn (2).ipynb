{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "# from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "\n",
        "# from torch import optim\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "2wVabjz3qdvE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "450c2fa6-7681-40f0-8f0a-a5fd36296b15"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)"
      ],
      "metadata": {
        "id": "kDWwcnDGBl6U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VNyUrkUfBp8M",
        "outputId": "649cbfc4-5767-43f0-f863-a4a073417d93"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.23.1-py2.py3-none-any.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=e61520f6dfcea19fa6d92d2e39af20d4d882e49a2b79ce8535148a47a2cc8cc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.23.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb"
      ],
      "metadata": {
        "id": "eYccTEjiCNGY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login(key='6264e29f109d3cf02a9911cd18b6725b79c489cd')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YIFAsysxClZQ",
        "outputId": "fa1cf05f-66f5-4b65-98ce-22d50da17135"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "import gdown \n",
        "# !conda install -y gdown\n",
        "import zipfile\n",
        "url = 'https://drive.google.com/u/0/uc?id=1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw&export=download'  \n",
        "gdown.download(url)\n",
        "z= zipfile.ZipFile('aksharantar_sampled.zip')\n",
        "z.extractall()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Wi4uEB7us20p",
        "outputId": "73290457-804e-46e2-ab03-1b1737811003"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/u/0/uc?id=1uRKU4as2NlS9i8sdLRS1e326vQRdhvfw&export=download\n",
            "To: /content/aksharantar_sampled.zip\n",
            "100%|██████████| 14.0M/14.0M [00:00<00:00, 134MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"aksharantar_sampled/tel/tel_train.csv\" , header = None)\n",
        "# df.head()\n",
        "df_val = pd.read_csv(\"aksharantar_sampled/tel/tel_valid.csv\" , header = None)\n",
        "df_test = pd.read_csv(\"aksharantar_sampled/tel/tel_test.csv\" , header = None)\n",
        "x1 = 0\n",
        "english_words_val = df_val[x1]\n",
        "english_words_test = df_test[x1]\n",
        "english_words = df[x1]\n",
        "telugu_words_val = df_val[x1+1]\n",
        "telugu_words_test = df_test[x1+1]\n",
        "telugu_words = df[x1+1]\n",
        "#print(df[50000:])"
      ],
      "metadata": {
        "id": "-8NGSmE_tnDW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findCharList(eng_words,tel_words):\n",
        "  english_char_list = []\n",
        "  max_length_word_english = -1\n",
        "  telugu_char_list = []\n",
        "  max_length_word_telugu = -1\n",
        "  for word in eng_words:\n",
        "    x2 = len(word)\n",
        "    x3 = max(max_length_word_english,x2)\n",
        "    max_length_word_english = x3\n",
        "    for char in word :\n",
        "      c = char\n",
        "      english_char_list.append(c);\n",
        "  english_char_list = set(english_char_list)\n",
        "  english_char_list = list(english_char_list)\n",
        "  for word in tel_words:\n",
        "    x4 = len(word)\n",
        "    x5 = max(max_length_word_telugu,x4)\n",
        "    max_length_word_telugu = x5\n",
        "    for char in word :\n",
        "      c1 =char\n",
        "      telugu_char_list.append(c1);\n",
        "  telugu_char_list = set(telugu_char_list)\n",
        "  telugu_char_list = list(telugu_char_list)\n",
        "  english_char_list.sort()\n",
        "  telugu_char_list.sort()\n",
        "  # print(len(telugu_char_list))\n",
        "  #print(telugu_char_list)\n",
        "  print(len(telugu_char_list))\n",
        "  return english_char_list,telugu_char_list,max_length_word_english,max_length_word_telugu"
      ],
      "metadata": {
        "id": "qpFjT-GZwshE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_char_list,telugu_char_list,max_length_word_english,max_length_word_telugu=findCharList(english_words,telugu_words)\n",
        "print(english_char_list)\n",
        "print(telugu_char_list)\n",
        "print(max_length_word_telugu)\n",
        "print(max_length_word_english)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LgPkLaOjxls3",
        "outputId": "3df81885-3fe2-43f2-d99b-460e5931afaa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62\n",
            "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "['ం', 'ః', 'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ', 'క', 'ఖ', 'గ', 'ఘ', 'చ', 'ఛ', 'జ', 'ఝ', 'ఞ', 'ట', 'ఠ', 'డ', 'ఢ', 'ణ', 'త', 'థ', 'ద', 'ధ', 'న', 'ప', 'ఫ', 'బ', 'భ', 'మ', 'య', 'ర', 'ఱ', 'ల', 'ళ', 'వ', 'శ', 'ష', 'స', 'హ', 'ా', 'ి', 'ీ', 'ు', 'ూ', 'ృ', 'ె', 'ే', 'ై', 'ొ', 'ో', 'ౌ', '్']\n",
            "21\n",
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for one word.\n",
        "def english_word2vec(word):\n",
        "  vec = []\n",
        "  x6 = len(english_char_list)+1\n",
        "  vec.append(x6)\n",
        "  for char in word:\n",
        "    c = char\n",
        "    x7 = len(english_char_list)\n",
        "    for i in range(x7):\n",
        "      x8 = english_char_list[i]\n",
        "      if(x8 == c):\n",
        "        vec.append(i+1)\n",
        "  x9 = max_length_word_english + 1\n",
        "  while(len(vec) < x9): \n",
        "      x10 = 0\n",
        "      vec.append(x10)\n",
        "  x11 = 0\n",
        "  vec.append(x11)\n",
        "  return (vec)"
      ],
      "metadata": {
        "id": "YdWiHudL00KX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def telugu_word2vec(word):\n",
        "  vec = []\n",
        "  x6 = len(telugu_char_list)+1\n",
        "  vec.append(x6)\n",
        "  for char in word:\n",
        "    c = char\n",
        "    x7 = len(telugu_char_list)\n",
        "    for i in range(x7):\n",
        "      x8 = telugu_char_list[i]\n",
        "      if(x8 == c):\n",
        "        vec.append(i+1)\n",
        "  x9 = max_length_word_telugu + 1\n",
        "  while(len(vec) < x9):  \n",
        "      x10 = 0\n",
        "      vec.append(x10)\n",
        "  x11 = 0\n",
        "  vec.append(x11)\n",
        "  return(vec)"
      ],
      "metadata": {
        "id": "sI523riu1gFh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vec = telugu_word2vec(telugu_words[10])\n",
        "# print(telugu_words[10])\n",
        "# print(vec)"
      ],
      "metadata": {
        "id": "84cRh6as1VxI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vec = english_word2vec(english_words[10])\n",
        "# print(english_words[10])\n",
        "# print(vec)"
      ],
      "metadata": {
        "id": "DuGljP2vsFNR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating matrix of representation for whole words of english and telugu.\n",
        "\n",
        "def ip_matrix_construct(words, lang):\n",
        "  ans = []\n",
        "  if(lang == \"english\"):\n",
        "    for word in words:\n",
        "      ans.append(english_word2vec(word))\n",
        "  else:\n",
        "    for word in words:\n",
        "      ans.append(telugu_word2vec(word))\n",
        "  return(ans)"
      ],
      "metadata": {
        "id": "d1wG87o92bfL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matrixRep(english_words,telugu_words,english_words_val,telugu_words_val,english_words_test,telugu_words_test):\n",
        "  # calculated representations of whole english and marathi words in variables english and marathi matrix.\n",
        "  eng = \"english\"\n",
        "  english_matrix = ip_matrix_construct(english_words, eng)\n",
        "  \n",
        "  english_matrix_val = ip_matrix_construct(english_words_val, eng)\n",
        "  english_matrix_test = ip_matrix_construct(english_words_test, eng)\n",
        "  english_matrix = torch.tensor(english_matrix)\n",
        "  english_matrix_val = torch.tensor(english_matrix_val)\n",
        "  english_matrix_test = torch.tensor(english_matrix_test)\n",
        "  \n",
        "  tel = \"telugu\"\n",
        "  telugu_matrix = ip_matrix_construct(telugu_words, tel)\n",
        " \n",
        "  telugu_matrix_val = ip_matrix_construct(telugu_words_val, tel)\n",
        "  telugu_matrix_test =ip_matrix_construct(telugu_words_test, tel)\n",
        "\n",
        "  telugu_matrix = torch.tensor(telugu_matrix) \n",
        "  telugu_matrix_val = torch.tensor(telugu_matrix_val)\n",
        "  telugu_matrix_test = torch.tensor(telugu_matrix_test)\n",
        "  \n",
        "  return english_matrix,telugu_matrix,english_matrix_val,telugu_matrix_val,english_matrix_test,telugu_matrix_test"
      ],
      "metadata": {
        "id": "xoDyG2_pDeap"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_matrix,telugu_matrix,english_matrix_val,telugu_matrix_val,english_matrix_test,telugu_matrix_test = matrixRep(english_words,telugu_words,english_words_val,telugu_words_val,english_words_test,telugu_words_test)"
      ],
      "metadata": {
        "id": "dbUc6SD0QqBa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,input_size, embedding_size, hidden_size, num_layers, dropout, cell_type, bidirectional,s=0.1):\n",
        "    super(Encoder,self).__init__()\n",
        "    ct = cell_type\n",
        "    self.cell_type = ct\n",
        "    dp = dropout\n",
        "    self.dropout = nn.Dropout(dp)\n",
        "    bd = bidirectional\n",
        "    self.bidirectional = bd\n",
        "    hs = hidden_size\n",
        "    self.hidden_size = hs\n",
        "    iS = input_size \n",
        "    self.embedding = nn.Embedding(iS, embedding_size)\n",
        "    nl = num_layers\n",
        "    self.num_layers = nl\n",
        "    s1 = s\n",
        "    self.s = s1\n",
        "    if(ct == \"LSTM\"):\n",
        "      self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = dropout, bidirectional = bidirectional)\n",
        "    elif(cell_type == \"RNN\"):\n",
        "      self.rnn = nn.RNN(embedding_size, hidden_size, num_layers, dropout = dropout, bidirectional = bidirectional)\n",
        "    elif(ct == \"GRU\"):\n",
        "      s1 = s1*2\n",
        "      self.gru = nn.GRU(embedding_size, hidden_size, num_layers, dropout = dropout, bidirectional = bidirectional)\n",
        "\n",
        "  def forward(self, x):\n",
        "    k = x\n",
        "    embedding = self.dropout(self.embedding(k))\n",
        "    ct1 = self.cell_type\n",
        "    if(ct1 == \"LSTM\"):\n",
        "      outputs, (hidden,cell) = self.lstm(embedding)\n",
        "      return hidden, cell\n",
        "    elif(ct1 == \"GRU\"):\n",
        "      output, hidden = self.gru(embedding)\n",
        "      return output, hidden\n",
        "    elif(ct1 == \"RNN\"):\n",
        "      output, hidden = self.rnn(embedding)\n",
        "      return output, hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-04T18:50:06.287093Z",
          "iopub.status.busy": "2023-05-04T18:50:06.286735Z",
          "iopub.status.idle": "2023-05-04T18:50:06.298555Z",
          "shell.execute_reply": "2023-05-04T18:50:06.297751Z"
        },
        "id": "abbae9cd",
        "papermill": {
          "duration": 0.026877,
          "end_time": "2023-05-04T18:50:06.300723",
          "exception": false,
          "start_time": "2023-05-04T18:50:06.273846",
          "status": "completed"
        },
        "tags": []
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers, dropout, cell_type,s=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "    ct = cell_type\n",
        "    self.cell_type = ct\n",
        "    hs = hidden_size\n",
        "    self.hidden_size = hs\n",
        "    dp = dropout\n",
        "    self.dropout = nn.Dropout(dp)\n",
        "    iS = input_size\n",
        "    self.embedding = nn.Embedding(iS, embedding_size)\n",
        "    self.s = s\n",
        "    nl = num_layers\n",
        "    self.num_layers = nl\n",
        "   \n",
        "    if(ct == \"LSTM\"):\n",
        "      self.lstm = nn.LSTM(embedding_size, hs, nl, dropout = dp)\n",
        "      es=embedding_size\n",
        "    elif(ct == \"GRU\"):\n",
        "      self.gru = nn.GRU(embedding_size, hs, nl, dropout = dp)\n",
        "    elif(ct == \"RNN\"):\n",
        "      self.rnn = nn.RNN(embedding_size, hs, nl, dropout = dp)\n",
        "      s=s*2\n",
        "    self.fc = nn.Linear(hs, output_size)  # fully connected.\n",
        "  \n",
        "  def forward(self, x, hidden, cell = 0):\n",
        "    y = x\n",
        "    y = y.unsqueeze(0).int()\n",
        "    embedding = self.dropout(self.embedding(y))\n",
        "    ct1 = self.cell_type\n",
        "\n",
        "    if(ct1 == \"LSTM\"):\n",
        "        outputs, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n",
        "    elif(ct1 == \"RNN\"):\n",
        "        outputs, hidden = self.rnn(embedding, hidden)\n",
        "    elif(ct1 == \"GRU\"):\n",
        "        outputs, hidden = self.gru(embedding, hidden)\n",
        " \n",
        "    predictions = self.fc(outputs)\n",
        "    predictions = predictions.squeeze(0)\n",
        "    if(ct1 == \"LSTM\"):\n",
        "        return predictions, hidden, cell\n",
        "    else:\n",
        "        return predictions, hidden\n",
        "\n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "metadata": {
        "id": "sk0Uvabyo7iz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, cell_type, bidirectional, num_layers,s=0.1):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        nl = num_layers\n",
        "        self.num_layers = nl\n",
        "        bd = bidirectional\n",
        "        self.bidirectional = bd\n",
        "        ct = cell_type\n",
        "        self.s = s\n",
        "        self.cell_type = ct\n",
        "        \n",
        "\n",
        "    def forward(self, source, target, teacher_force_ratio=0.5,p=0.1):\n",
        "        t2 = target.shape[0]\n",
        "        target_len = t2\n",
        "        s2 = source.shape[1]\n",
        "        batch_size = s2\n",
        "        tcl = len(telugu_char_list)\n",
        "        target_vocab_size = tcl + 2  # intitially = 66 || Now 63 + 1(start token) + 1 = 65\n",
        "        tvs = target_vocab_size\n",
        "        outputs = torch.zeros(t2, s2, tvs).to(device)\n",
        "        ct3 = self.cell_type\n",
        "        if(ct3 == \"GRU\"):\n",
        "            output, hidden = self.encoder(source)\n",
        "        elif(ct3 == \"RNN\"):\n",
        "            output, hidden = self.encoder(source)\n",
        "        else:\n",
        "            hidden, cell = self.encoder(source)\n",
        "        bd3 = self.bidirectional \n",
        "        sl3 = self.num_layers\n",
        "        if(bd3 == True):\n",
        "            hidden = hidden[sl3 - 1] + hidden[sl3 - 1]\n",
        "            hidden = hidden.repeat(sl3,1,1)\n",
        "            if(self.cell_type == \"LSTM\"):\n",
        "                cell = cell[sl3 - 1] + cell[sl3 - 1]\n",
        "                cell = cell.repeat(sl3,1,1)\n",
        "                \n",
        "        x = target[0]\n",
        "        s5=0.2\n",
        "        for t in range(t2-1):\n",
        "            if(ct3 == \"LSTM\"):\n",
        "                output, hidden, cell = self.decoder(x, hidden, cell)\n",
        "                s5=s5*2\n",
        "            else :\n",
        "                output, hidden = self.decoder(x, hidden)\n",
        "                s5=s5+2\n",
        "\n",
        "            outputs[t+1] = output\n",
        "            best_guess = output.argmax(1)\n",
        "            y = output\n",
        "            x = target[t+1] if random.random() < teacher_force_ratio else best_guess\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "N3etjdNwp0Jk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def findDecoderInputSize():\n",
        "#   x = len(telugu_char_list)\n",
        "#   return x"
      ],
      "metadata": {
        "id": "1uuTRKiebHbc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def findEncoderInputSize():\n",
        "#   x = len(english_char_list)\n",
        "#   return x"
      ],
      "metadata": {
        "id": "SkbDXhlna2C5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Evaluate(model, english_matrix, telugu_matrix, epoch, batch_size,s=0.1):\n",
        "    correct_count = 0\n",
        "    bat = (int)(len(english_matrix) / batch_size)\n",
        "    for batch_idx in range(1,bat+1):\n",
        "        inp_data = english_matrix[batch_size * (batch_idx-1) : batch_size * (batch_idx)].to(device)\n",
        "        id = inp_data\n",
        "        bs = batch_size\n",
        "        target = telugu_matrix[bs * (batch_idx-1) : bs * (batch_idx)].to(device)\n",
        "        tgt = target\n",
        "        output = model.forward(id.T, tgt.T, 0)\n",
        "        s1=s\n",
        "        output = nn.Softmax(dim=2)(output)\n",
        "        #s1=s1*bs\n",
        "        output = torch.argmax(output, dim=2)\n",
        "        ot = output\n",
        "        output = ot.T\n",
        "\n",
        "        for i in range(1,bs+1):\n",
        "            if(torch.equal(output[i-1][1:],target[i-1][1:])):\n",
        "                k = correct_count\n",
        "                correct_count = k+1\n",
        "    l5 = len(english_matrix)\n",
        "    accuracy = correct_count * 100 / l5\n",
        "    return accuracy\n",
        "        "
      ],
      "metadata": {
        "id": "Eo2VDhLNw4VA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neural_network(cell_type, bidirectional, num_layers, batch_size, embedding_size, hidden_size, dropout,num_epochs=5,learning_rate=0.001):\n",
        "  x=len(english_char_list)\n",
        "  y=len(telugu_char_list)\n",
        "  input_size_encoder = x + 2   \n",
        "  input_size_decoder = y + 2  \n",
        "  output_size        = y + 2  \n",
        "  s=0.2\n",
        "  encoder_net = Encoder(input_size_encoder, embedding_size, hidden_size, num_layers, dropout, cell_type,bidirectional).to(device)\n",
        "  s=s+1\n",
        "  decoder_net = Decoder(input_size_decoder,embedding_size,hidden_size,output_size,num_layers,dropout, cell_type).to(device)\n",
        "  pad_idx = 63\n",
        "  model = Seq2Seq(encoder_net, decoder_net, cell_type, bidirectional, num_layers).to(device)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  \n",
        "  criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
        "\n",
        "  # train_loss = []\n",
        "  # train_accuracy = []\n",
        "  # val_accuracy = []\n",
        "  for epoch in range(1,num_epochs+1):\n",
        "      ep = epoch-1\n",
        "      print(\"epoch = \",ep)\n",
        "\n",
        "      model.train()\n",
        "      step = 0\n",
        "      total_loss = 0\n",
        "      bat = (int)(len(english_matrix) / batch_size)\n",
        "      for batch_idx in range(1,bat+1):\n",
        "          \n",
        "          bi = batch_idx\n",
        "          inp_data = english_matrix[batch_size * (bi-1) : batch_size * (bi)].to(device)\n",
        "          target = telugu_matrix[batch_size * (bi-1) : batch_size * (bi)].to(device)\n",
        "\n",
        "          target = target.T\n",
        "          output = model(inp_data.T, target)\n",
        "          step1 = step\n",
        "          output = output[1:].reshape(-1, output.shape[2])\n",
        "          s=0\n",
        "          target = target[1:].reshape(-1)\n",
        "          optimizer.zero_grad()\n",
        "          loss = criterion(output, target)\n",
        "          l1 = loss\n",
        "          total_loss = total_loss + loss\n",
        "          loss.backward()\n",
        "\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "          optimizer.step()\n",
        "          s=s+1\n",
        "          step = step + 1\n",
        "  #     print(\"total loss = \",total_loss / (len(english_matrix) * len(marathi_matrix[0])))\n",
        "      tl = total_loss/step\n",
        "      print(\"total loss = \",tl)\n",
        "      #train_loss.append(tl)\n",
        "      training_accuracy = Evaluate(model, english_matrix, telugu_matrix, ep, batch_size)\n",
        "      print(\"Training Accuracy = \", training_accuracy)\n",
        "      s+=1\n",
        "      #train_accuracy.append(training_accuracy)\n",
        "      val_accuracy = Evaluate(model, english_matrix_val, telugu_matrix_val, ep, batch_size)\n",
        "      print(\"Validation accuracy = \",val_accuracy)\n",
        "      wandb.log({\"train_accuracy\": training_accuracy, \"validation_accuracy\": val_accuracy, \"training_loss\": total_loss / step,  'epoch': ep})\n",
        "  #return train_loss,train_accuracy,val_accuracy"
      ],
      "metadata": {
        "id": "a9NHrnmtzxMG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cell_type = \"GRU\"\n",
        "# bidirectional = True\n",
        "# num_layers = 3\n",
        "# batch_size = 64\n",
        "# embedding_size = 128\n",
        "# hidden_size = 32\n",
        "# dropout = 0.3\n",
        "# a,b,c=neural_network(cell_type, bidirectional, num_layers, batch_size, embedding_size, hidden_size, dropout)"
      ],
      "metadata": {
        "id": "3jhaic16Q7YY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sweep_config = {\n",
        "#     \"method\": 'bayes', #grid, random\n",
        "#     \"metric\": {\n",
        "#       \"name\": 'validation_accuracy',\n",
        "#       \"goal\": 'maximize', \n",
        "#     },\n",
        "#     \"parameters\": {\n",
        "#         \"epochs\": {\n",
        "#             \"values\": [15]\n",
        "#         },\n",
        "#         \"dropout\": {\n",
        "#             \"values\": [0.5]\n",
        "#         },\n",
        "#         \"hidden_size\": {\n",
        "#             \"values\": [256]\n",
        "#         },\n",
        "#         \"embedding_size\": {\n",
        "#             \"values\": [128]\n",
        "#         },\n",
        "#         \"learning_rate\":{\n",
        "#             \"values\":[0.001]\n",
        "#         },\n",
        "#         \"batch_size\":{\n",
        "#             \"values\":[128]\n",
        "#         },\n",
        "#         \"num_layers\":{\n",
        "#             \"values\":[2]\n",
        "#        },\n",
        "#         \"bidirectional\":{\n",
        "#             \"values\":[False]\n",
        "#         },\n",
        "#         \"cell_type\":{\n",
        "#             \"values\":['LSTM']\n",
        "#         }\n",
        "#     }\n",
        "# }"
      ],
      "metadata": {
        "id": "i2k3u7LQg-nL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    \"method\": 'bayes', #grid, random\n",
        "    \"metric\": {\n",
        "      \"name\": 'validation_accuracy',\n",
        "      \"goal\": 'maximize', \n",
        "    },\n",
        "    \"parameters\": {\n",
        "        \"epochs\": {\n",
        "            \"values\": [15]\n",
        "        },\n",
        "        \"dropout\": {\n",
        "            \"values\": [0.3,0.4,0.5]\n",
        "        },\n",
        "        \"hidden_size\": {\n",
        "            \"values\": [128,256,512]\n",
        "        },\n",
        "        \"embedding_size\": {\n",
        "            \"values\": [128,256,512]\n",
        "        },\n",
        "        \"learning_rate\":{\n",
        "            \"values\":[0.001,0.05]\n",
        "        },\n",
        "        \"batch_size\":{\n",
        "            \"values\":[32,64,128,256]\n",
        "        },\n",
        "        \"num_layers\":{\n",
        "            \"values\":[1,3,2]\n",
        "       },\n",
        "        \"bidirectional\":{\n",
        "            \"values\":[False,True]\n",
        "        },\n",
        "        \"cell_type\":{\n",
        "            \"values\":['LSTM','RNN','GRU']\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "yU8GaMtMDaKf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sweep_config = {\n",
        "#   \"name\": \"CS6910 Assignment 3\",\n",
        "#   \"metric\": {\n",
        "#       \"name\":\"validation_accuracy\",\n",
        "#       \"goal\": \"maximize\"\n",
        "#   },\n",
        "#   \"method\": \"bayes\",\n",
        "#   \"parameters\": {\n",
        "        \n",
        "#         \"cell_type\": {\n",
        "#             \"values\": [\"GRU\", \"RNN\", \"LSTM\"]\n",
        "#         },\n",
        "#         \"learning_rate\":{\n",
        "#             \"values\":[0.001,0.05]\n",
        "#         },\n",
        "#         \"epochs\": {\n",
        "#             \"values\": [15]\n",
        "#         },\n",
        "#         \"bidirectional\": {\n",
        "#             \"values\": [True, False]\n",
        "#         },\n",
        "#         \"num_layers\": {\n",
        "#             \"values\": [1, 2, 3]\n",
        "#         },\n",
        "#         \"batch_size\": {\n",
        "#             \"values\": [32,64,128]\n",
        "#         },\n",
        "#         \"embedding_size\": {\n",
        "#             \"values\": [16, 32, 64,128, 256, 384, 512]\n",
        "#         },\n",
        "#         \"hidden_size\": {\n",
        "#             \"values\": [16,32,64,128, 256, 384, 512]\n",
        "#         },\n",
        "#         \"dropout\": {\n",
        "#             \"values\": [0.2,0.3,0.4,0.5]\n",
        "#         }\n",
        "#     }\n",
        "# }\n"
      ],
      "metadata": {
        "id": "1wB0iES3AykX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "   \n",
        "    wandb.init()\n",
        "\n",
        "    #wandb.init()\n",
        "\n",
        "    # Config is a variable that holds and saves hyperparameters and inputs\n",
        "    config = wandb.config\n",
        "\n",
        "    name=\"ct_\"+str(wandb.config.cell_type)+\"_bd_\"+str(wandb.config.bidirectional)+\"_nl_\"+str(wandb.config.num_layers)+\"_bs_\"+str(wandb.config.batch_size)+\"_es_\"+str(wandb.config.embedding_size)+\"_hs_\"+str(wandb.config.hidden_size)+\"_dp_\"+str(wandb.config.dropout)\n",
        "    print(name)\n",
        "    wandb.run.name = name\n",
        "   \n",
        "    neural_network(cell_type=config.cell_type, bidirectional=config.bidirectional, num_layers=config.num_layers,batch_size = config.batch_size,embedding_size=config.embedding_size,hidden_size=config.hidden_size,dropout=config.dropout,num_epochs=config.epochs,learning_rate=config.learning_rate)\n",
        "\n",
        "  \n",
        "\n",
        "   \n",
        "\n",
        "    wandb.finish()"
      ],
      "metadata": {
        "id": "Me4nUwM8Le9v"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, entity=\"cs22m043\", project=\"Assignment3\")\n",
        "wandb.agent(sweep_id, train, count=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2054
        },
        "id": "uZWVc5RgBFxS",
        "outputId": "4bf67c85-0702-42a1-82f7-f822d96f497a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: nqjwyyj7\n",
            "Sweep URL: https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nfyf87hy with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m043\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230518_154611-nfyf87hy</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m043/Assignment3/runs/nfyf87hy' target=\"_blank\">fiery-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m043/Assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m043/Assignment3' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m043/Assignment3/runs/nfyf87hy' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3/runs/nfyf87hy</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ct_LSTM_bd_False_nl_2_bs_128_es_128_hs_256_dp_0.5\n",
            "epoch =  0\n",
            "total loss =  tensor(1.5998, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  0.0\n",
            "Validation accuracy =  0.0\n",
            "epoch =  1\n",
            "total loss =  tensor(1.1064, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  1.662109375\n",
            "Validation accuracy =  4.150390625\n",
            "epoch =  2\n",
            "total loss =  tensor(0.6458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  9.802734375\n",
            "Validation accuracy =  15.8447265625\n",
            "epoch =  3\n",
            "total loss =  tensor(0.4578, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  18.763671875\n",
            "Validation accuracy =  24.462890625\n",
            "epoch =  4\n",
            "total loss =  tensor(0.3707, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  24.75390625\n",
            "Validation accuracy =  27.587890625\n",
            "epoch =  5\n",
            "total loss =  tensor(0.3165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  31.138671875\n",
            "Validation accuracy =  33.837890625\n",
            "epoch =  6\n",
            "total loss =  tensor(0.2800, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  34.568359375\n",
            "Validation accuracy =  34.3505859375\n",
            "epoch =  7\n",
            "total loss =  tensor(0.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  38.177734375\n",
            "Validation accuracy =  37.2314453125\n",
            "epoch =  8\n",
            "total loss =  tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  41.64453125\n",
            "Validation accuracy =  40.0634765625\n",
            "epoch =  9\n",
            "total loss =  tensor(0.2139, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  43.796875\n",
            "Validation accuracy =  41.1376953125\n",
            "epoch =  10\n",
            "total loss =  tensor(0.2001, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  46.392578125\n",
            "Validation accuracy =  41.9677734375\n",
            "epoch =  11\n",
            "total loss =  tensor(0.1911, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  47.87890625\n",
            "Validation accuracy =  43.0419921875\n",
            "epoch =  12\n",
            "total loss =  tensor(0.1785, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  49.701171875\n",
            "Validation accuracy =  43.798828125\n",
            "epoch =  13\n",
            "total loss =  tensor(0.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  50.869140625\n",
            "Validation accuracy =  44.921875\n",
            "epoch =  14\n",
            "total loss =  tensor(0.1625, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Training Accuracy =  53.380859375\n",
            "Validation accuracy =  45.8740234375\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>train_accuracy</td><td>▁▁▂▃▄▅▆▆▆▇▇▇███</td></tr><tr><td>training_loss</td><td>█▆▃▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>validation_accuracy</td><td>▁▂▃▅▅▆▆▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_accuracy</td><td>53.38086</td></tr><tr><td>training_loss</td><td>0.16245</td></tr><tr><td>validation_accuracy</td><td>45.87402</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fiery-sweep-1</strong> at: <a href='https://wandb.ai/cs22m043/Assignment3/runs/nfyf87hy' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3/runs/nfyf87hy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230518_154611-nfyf87hy/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9o9c69sn with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230518_155229-9o9c69sn</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m043/Assignment3/runs/9o9c69sn' target=\"_blank\">light-sweep-2</a></strong> to <a href='https://wandb.ai/cs22m043/Assignment3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m043/Assignment3' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3/sweeps/nqjwyyj7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m043/Assignment3/runs/9o9c69sn' target=\"_blank\">https://wandb.ai/cs22m043/Assignment3/runs/9o9c69sn</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ct_LSTM_bd_False_nl_2_bs_128_es_128_hs_256_dp_0.5\n",
            "epoch =  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# id = wandb.sweep(sweep_config, project=\"Assignment3\", entity =\"cs22m043\")\n",
        "# wandb.agent(id, function=train)"
      ],
      "metadata": {
        "id": "wWumB8s4LuJG"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}